{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77a8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432c0892",
   "metadata": {},
   "source": [
    "# Model training comparison with a ground truth (entire slice manually segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c3e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"C:\\\\Users\\\\lauri\\\\OneDrive - Danmarks Tekniske Universitet\\\\Dokumenter\\\\GitHub\\\\segmenter\\\\notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "408ff298",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9688392",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4e38cb8",
   "metadata": {},
   "source": [
    "Job 5272987912 = Model only trained from rough annotation data\n",
    "Job 6501045458 = Model trained from the rough annotation data + several iterations (7-8) of user inputs => Not final training achieved (still improvements to be done but definitively good improvements made from the \"untrained\" state)\n",
    "Initial volume for input: QJ2_25nm_bas_v1.tif\n",
    "training pool: parsing 10 slices starting from the first one (included) until no slice remain (indexing from 1: 1-11-21-...-1581-1591).\n",
    "For comparison with the full slice manually annotated:\n",
    "    manual annotaion: QJ2_25nm_bas_v1_01093_correcMan.tif\n",
    "    Model output \"untrained\" (only rough): rough.tif\n",
    "    Model output trained: trained.tif\n",
    "Initial input for the segmentation: QJ2_25nm_bas_v1_01093.tif\n",
    "\n",
    "Grey level labels in annotated images (the higher the value the whiter the phase in the image plots for cmap=\"gray\"):\n",
    "    Graphite (acitve material): 242\n",
    "    Conductive binder (CMC+SBR+carbon black?): 191\n",
    "    Porosity: 89\n",
    "    Outside (not in the material - comes from the imaging and reconstruction processes): 26\n",
    "    \n",
    "The slice for manual annotation has been chosen randomly making sure to exclude any slice from the volume pertaining to the pool the model uses to check for the addition of new data in the training loop with the human user. This has been done to avoid any biases coming from the model and the training pool.\n",
    "\n",
    "/!\\ Slice indices in the file names are base 1 (+1 compared to python indicies starting at 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2973503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_initial = io.imread(\"QJ2_25nm_bas_v1_01093.tif\")\n",
    "image_manual = io.imread(\"QJ2_25nm_bas_v1_01093_correcMan.tif\")\n",
    "image_rough = io.imread(\"rough.tif\")\n",
    "image_trained = io.imread(\"trained_2.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global visualistaion of the initial image and the outputs from the three segmentations\n",
    "fig1, axes1 = plt.subplots(1, 4, figsize=(15, 5), sharey=True)\n",
    "axes1[0].imshow(image_initial, cmap=\"gray\", interpolation=None)\n",
    "axes1[0].set_title(\"Initial image\")\n",
    "axes1[1].imshow(image_rough, cmap=\"gray\", interpolation=None)\n",
    "axes1[1].set_title(\"Untrained model\")\n",
    "axes1[2].imshow(image_manual, cmap=\"gray\", interpolation=None)\n",
    "axes1[2].set_title(\"Manual annotation (ground truth)\")\n",
    "axes1[3].imshow(image_trained, cmap=\"gray\", interpolation=None)\n",
    "axes1[3].set_title(\"Trained model\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69e8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed18b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering pixel counts for phase fraction estimations\n",
    "def get_pixel_count(image):\n",
    "    greyLevel_values = np.unique(image)\n",
    "    data = {}\n",
    "    count = []\n",
    "    global_count = 0\n",
    "    for value in greyLevel_values:\n",
    "        temp = (image==value).sum()\n",
    "        count.append(temp)\n",
    "        global_count += temp\n",
    "#         print(value, count, global_count)\n",
    "    assert global_count == image.size, \"Warning, gloabal count does not match total number of pixels in the image.\"\n",
    "    data[\"value\"], data[\"pixel count\"] = greyLevel_values, np.array(count)\n",
    "    return data\n",
    "\n",
    "data_manual = get_pixel_count(image_manual)\n",
    "data_rough = get_pixel_count(image_rough)\n",
    "data_trained = get_pixel_count(image_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ffb797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dice_score_no_outside(image1, image2):\n",
    "    assert image1.shape == image2.shape, \"Warning, images must have the same shape.\"\n",
    "    classes = np.unique(image1)\n",
    "    print(classes)\n",
    "    num_classes = len(classes)\n",
    "    dice_score = np.zeros(num_classes)\n",
    "    for i in range(num_classes):\n",
    "        if classes[i] != 26:\n",
    "            dice_score[i] = 2* ((image1 == classes[i] )& (image2 == classes[i])).sum() / ((image1 == classes[i]).sum() + (image2 == classes[i]).sum())\n",
    "    return dice_score.sum() / (num_classes-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3251d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dice_score(image1, image2):\n",
    "    assert image1.shape == image2.shape, \"Warning, images must have the same shape.\"\n",
    "    classes = np.unique(image1)\n",
    "    print(classes)\n",
    "    num_classes = len(classes)\n",
    "    dice_score = np.zeros(num_classes)\n",
    "    for i in range(num_classes):\n",
    "\n",
    "        dice_score[i] = 2* ((image1 == classes[i] )& (image2 == classes[i])).sum() / ((image1 == classes[i]).sum() + (image2 == classes[i]).sum())\n",
    "    return dice_score.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f80556",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dice_score(image_manual, image_rough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dice_score(image_manual, image_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17125390",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dice_score(image_manual, image_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f30c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get phase fractions\n",
    "# Label 26 does not count in phase fractions => Not actual material (\"outside\" later)\n",
    "\n",
    "labels_to_avoid = [26]\n",
    "\n",
    "def get_phase_fractions(data, labels_to_avoid):\n",
    "    total_count = 0\n",
    "    for value in data[\"value\"]:\n",
    "        if value in labels_to_avoid:\n",
    "            pass\n",
    "        else:\n",
    "            total_count += data[\"pixel count\"][data[\"value\"]==value]\n",
    "    phase_fractions = []\n",
    "    for value in data[\"value\"]:\n",
    "        if value in labels_to_avoid:\n",
    "            phase_fractions.append(0.)\n",
    "        else:\n",
    "            phase_fractions.append(float(data[\"pixel count\"][data[\"value\"]==value]/total_count))\n",
    "    test = np.array(phase_fractions).sum()\n",
    "    assert test == 1, \"Warning, phase fractions do not account to 1 in total: {}\".format(test)\n",
    "    data[\"phase fraction\"] = np.array(phase_fractions)\n",
    "    \n",
    "get_phase_fractions(data_manual, labels_to_avoid)\n",
    "get_phase_fractions(data_rough, labels_to_avoid)\n",
    "get_phase_fractions(data_trained, labels_to_avoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a1e537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase reparition per segmentation\n",
    "fig2, axes2 = plt.subplots(1, 3, figsize=(15, 10))\n",
    "pp1 = axes2[0].pie(data_rough[\"phase fraction\"][data_rough[\"value\"]!=26], \n",
    "                   labels=[\"Porosity - {:.2%}\".format(float(data_rough[\"phase fraction\"][data_rough[\"value\"]==89])),\n",
    "                           \"Conductive binder - {:.2%}\".format(float(data_rough[\"phase fraction\"][data_rough[\"value\"]==191])),\n",
    "                           \"Graphite - {:.2%}\".format(float(data_rough[\"phase fraction\"][data_rough[\"value\"]==242]))])\n",
    "axes2[0].set_title(\"Untrained Model\")\n",
    "axes2[1].pie(data_manual[\"phase fraction\"][data_manual[\"value\"]!=26],\n",
    "             labels=[\"Porosity - {:.2%}\".format(float(data_manual[\"phase fraction\"][data_manual[\"value\"]==89])),\n",
    "                     \"Conductive binder - {:.2%}\".format(float(data_manual[\"phase fraction\"][data_manual[\"value\"]==191])),\n",
    "                     \"Graphite - {:.2%}\".format(float(data_manual[\"phase fraction\"][data_manual[\"value\"]==242]))])\n",
    "axes2[1].set_title(\"Manual annotation (ground truth)\")\n",
    "axes2[2].pie(data_trained[\"phase fraction\"][data_trained[\"value\"]!=26], \n",
    "             labels=[\"Porosity - {:.2%}\".format(float(data_trained[\"phase fraction\"][data_trained[\"value\"]==89])),\n",
    "                     \"Conductive binder - {:.2%}\".format(float(data_trained[\"phase fraction\"][data_trained[\"value\"]==191])),\n",
    "                     \"Graphite - {:.2%}\".format(float(data_trained[\"phase fraction\"][data_trained[\"value\"]==242]))])\n",
    "axes2[2].set_title(\"Trained Model\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fdee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phase fractions per phase depending on the segmentation\n",
    "phases = [\"Porosity\", \"Conductive binder\", \"Graphite\"]\n",
    "segmentations = {\"Untrained\": data_rough[\"phase fraction\"][data_rough[\"value\"]!=26]*100,\n",
    "                 \"Manual\": data_manual[\"phase fraction\"][data_manual[\"value\"]!=26]*100,\n",
    "                 \"Trained\": data_trained[\"phase fraction\"][data_trained[\"value\"]!=26]*100}\n",
    "\n",
    "fig3, axes3 = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "x = np.arange(len(phases))\n",
    "width = 0.25\n",
    "multiplier = 0\n",
    "\n",
    "for attribute, measurement in segmentations.items():\n",
    "    offset = width * multiplier\n",
    "    rects = axes3.bar(x + offset, measurement, width, label=attribute)\n",
    "    axes3.bar_label(rects, fmt=\"%.2f\", padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "axes3.set_ylabel(\"Phase fraction (%)\")\n",
    "axes3.set_xticks(x + width, phases)\n",
    "axes3.legend(loc=9, ncol=3, frameon=False)\n",
    "axes3.set_ylim(0, 55)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41926ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differences comming from wrongly segmenting the \"outside\" => not actual material\n",
    "out_manual = float(data_manual[\"pixel count\"][data_manual[\"value\"]==26])\n",
    "out_rough = float(data_rough[\"pixel count\"][data_rough[\"value\"]==26])\n",
    "out_trained = float(data_trained[\"pixel count\"][data_trained[\"value\"]==26])\n",
    "\n",
    "relative_difference_rough = (out_rough - out_manual) / out_manual\n",
    "relative_difference_trained = (out_trained - out_manual) / out_manual\n",
    "relative_difference_training = (out_rough - out_trained) / out_trained\n",
    "\n",
    "print(\"\"\"Relative differences comming from wrongly labelling the outside area in the images (not actual material):\n",
    "- Regarding the \"outside label\":\n",
    "    Untrained model vs. manual segmentation: {:.2%}\n",
    "    Trained model vs. manual segmentation: {:.2%}\n",
    "    Untrained vs. trained model: {:.2%}\n",
    "\"\"\".format(relative_difference_rough, relative_difference_trained, relative_difference_training))\n",
    "\n",
    "material_manual = data_manual[\"pixel count\"][data_manual[\"value\"]!=26].sum()\n",
    "material_rough = data_rough[\"pixel count\"][data_rough[\"value\"]!=26].sum()\n",
    "material_trained = data_trained[\"pixel count\"][data_trained[\"value\"]!=26].sum()\n",
    "\n",
    "relative_difference_rough = (material_rough - material_manual) / material_manual\n",
    "relative_difference_trained = (material_trained - material_manual) / material_manual\n",
    "relative_difference_training = (material_rough - material_trained) / material_trained\n",
    "\n",
    "print(\"\"\"- Regarding the sample identification (material vs. not material):\n",
    "    Untrained model vs. manual segmentation: {:.2%}\n",
    "    Trained model vs. manual segmentation: {:.2%}\n",
    "    Untrained vs. trained model: {:.2%}\n",
    "\"\"\".format(relative_difference_rough, relative_difference_trained, relative_difference_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3bf980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differences in segmentation relatively to each phase (maps/images)\n",
    "image_diff_rough = (image_rough != image_manual)\n",
    "alpha_mask_rough = image_diff_rough.astype(\"f\")\n",
    "\n",
    "image_diff_trained = (image_trained != image_manual)\n",
    "alpha_mask_trained = image_diff_trained.astype(\"f\")\n",
    "\n",
    "cmap = \"plasma\"\n",
    "fig4, axes4 = plt.subplots(2, 2, figsize=(15, 20), sharey=True)\n",
    "axes4[0][0].imshow(image_rough, cmap=cmap, interpolation=None)\n",
    "axes4[0][0].set_title(\"Untrained model segmentation\")\n",
    "axes4[0][1].imshow(image_rough, alpha=alpha_mask_rough, cmap=cmap, interpolation=None)\n",
    "axes4[0][1].set_title(\"Errors relative to the manual segmentation\")\n",
    "axes4[1][0].imshow(image_trained, cmap=cmap, interpolation=None)\n",
    "axes4[1][0].set_title(\"Trained model segmentation\")\n",
    "axes4[1][1].imshow(image_rough, alpha=alpha_mask_trained, cmap=cmap, interpolation=None)\n",
    "axes4[1][1].set_title(\"Errors relative to the manual segmentation\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053c1cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = \"plasma\"\n",
    "fig5, axes5 = plt.subplots(2, 3, figsize=(15, 15), sharey=True)\n",
    "axes5[0][0].imshow(image_rough, cmap=cmap, interpolation=None)\n",
    "axes5[0][0].set_title(\"Untrained model segmentation\")\n",
    "axes5[0][1].imshow(image_rough, alpha=alpha_mask_rough, cmap=cmap, interpolation=None)\n",
    "axes5[0][1].set_title(\"Errors relative to the manual segmentation\")\n",
    "axes5[0][2].imshow(image_manual, alpha=alpha_mask_rough, cmap=cmap, interpolation=None)\n",
    "axes5[0][2].set_title(\"Actual phases in the manual segmentation\")\n",
    "axes5[1][0].imshow(image_trained, cmap=cmap, interpolation=None)\n",
    "axes5[1][0].set_title(\"Trained model segmentation\")\n",
    "axes5[1][1].imshow(image_rough, alpha=alpha_mask_trained, cmap=cmap, interpolation=None)\n",
    "axes5[1][1].set_title(\"Errors relative to the manual segmentation\")\n",
    "axes5[1][2].imshow(image_manual, alpha=alpha_mask_trained, cmap=cmap, interpolation=None)\n",
    "axes5[1][2].set_title(\"Actual phases in the manual segmentation\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8496385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global visualistaion of the initial image and the outputs from the three segmentations\n",
    "cmap = \"viridis\"\n",
    "fig1, axes1 = plt.subplots(1, 4, figsize=(15, 5), sharey=True)\n",
    "axes1[0].imshow(image_initial, cmap=\"gray\", interpolation=None)\n",
    "axes1[0].set_title(\"Initial image\", fontsize=15)\n",
    "axes1[1].imshow(image_manual, cmap=\"viridis\", interpolation=None)\n",
    "axes1[1].set_title(\"Manual annotation\", fontsize=15)\n",
    "axes1[2].imshow(image_rough, alpha=alpha_mask_rough, cmap=cmap, interpolation=None)\n",
    "axes1[2].set_title(\"Error (Base model)\", fontsize=15)\n",
    "axes1[3].imshow(image_trained, alpha=alpha_mask_trained, cmap=cmap, interpolation=None)\n",
    "axes1[3].set_title(\"Error (Trained model)\", fontsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(\"segmentation_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4061e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b311b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differences in segmentation relatively to each phase (numbers)\n",
    "am_manual = float(data_manual[\"pixel count\"][data_manual[\"value\"]==242])\n",
    "am_rough = float(data_rough[\"pixel count\"][data_rough[\"value\"]==242])\n",
    "am_trained = float(data_trained[\"pixel count\"][data_trained[\"value\"]==242])\n",
    "\n",
    "relative_difference_rough = (am_rough - am_manual) / am_manual\n",
    "relative_difference_trained = (am_trained - am_manual) / am_manual\n",
    "relative_difference_training = (am_rough - am_trained) / am_trained\n",
    "\n",
    "print(\"\"\"Relative differences comming from wrongly labelling phases in the images:\n",
    "- Regarding the active material (graphite):\n",
    "    Untrained model vs. manual segmentation: {:.2%}\n",
    "    Trained model vs. manual segmentation: {:.2%}\n",
    "    Untrained vs. trained model: {:.2%}\n",
    "\"\"\".format(relative_difference_rough, relative_difference_trained, relative_difference_training))\n",
    "\n",
    "cb_manual = float(data_manual[\"pixel count\"][data_manual[\"value\"]==191])\n",
    "cb_rough = float(data_rough[\"pixel count\"][data_rough[\"value\"]==191])\n",
    "cb_trained = float(data_trained[\"pixel count\"][data_trained[\"value\"]==191])\n",
    "\n",
    "relative_difference_rough = (cb_rough - cb_manual) / cb_manual\n",
    "relative_difference_trained = (cb_trained - cb_manual) / cb_manual\n",
    "relative_difference_training = (cb_rough - cb_trained) / cb_trained\n",
    "\n",
    "print(\"\"\"- Regarding the conductive binder:\n",
    "    Untrained model vs. manual segmentation: {:.2%}\n",
    "    Trained model vs. manual segmentation: {:.2%}\n",
    "    Untrained vs. trained model: {:.2%}\n",
    "\"\"\".format(relative_difference_rough, relative_difference_trained, relative_difference_training))\n",
    "\n",
    "poro_manual = float(data_manual[\"pixel count\"][data_manual[\"value\"]==89])\n",
    "poro_rough = float(data_rough[\"pixel count\"][data_rough[\"value\"]==89])\n",
    "poro_trained = float(data_trained[\"pixel count\"][data_trained[\"value\"]==89])\n",
    "\n",
    "relative_difference_rough = (poro_rough - poro_manual) / poro_manual\n",
    "relative_difference_trained = (poro_trained - poro_manual) / poro_manual\n",
    "relative_difference_training = (poro_rough - poro_trained) / poro_trained\n",
    "\n",
    "print(\"\"\"- Regarding the porosity:\n",
    "    Untrained model vs. manual segmentation: {:.2%}\n",
    "    Trained model vs. manual segmentation: {:.2%}\n",
    "    Untrained vs. trained model: {:.2%}\n",
    "\"\"\".format(relative_difference_rough, relative_difference_trained, relative_difference_training))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b87a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save phase fraction and pixel count data as .csv files per segmentaion\n",
    "df_rough = pd.DataFrame(data_rough)\n",
    "df_rough.to_csv(\"Rough_segmentation.csv\")\n",
    "\n",
    "df_trained = pd.DataFrame(data_trained)\n",
    "df_trained.to_csv(\"Trained_segmentation.csv\")\n",
    "\n",
    "df_manual = pd.DataFrame(data_manual)\n",
    "df_manual.to_csv(\"Manual_segmentation.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d856a22b",
   "metadata": {},
   "source": [
    "Concluding thoughts:\n",
    "- Most of the phase fraction variations seem to revolve around the porosity and conductive binder phases. Active material (graphite) seems fairly stable. Semi-expected as the most difficult phase to segment is the conductive binder, however from a human eye the uncertainty is as much in the interfaces between binder and graphite as it is between binder and porosity.\n",
    "- The discrimination between the sample and the outside area (not material) coming from imaging/reconstruction seems good and not varying a lot with training => Not a huge source of uncertainty here from the model (good)\n",
    "- From the error maps, most of the uncertainty is around the interfaces (expected as it is where the image acquisition precision is challenged). Plus, it mostly concerns the binder phase relatively to the porosity, in correlations with the other metrics. However, some errors appear to be more \"bulk\" in some areas, visual inspection of the initial image (and volume) shows that these are areas where the image quality seems locally degraded (due to reconstruction artefacts or interfaces parallel to the image plan for example). It also shows that some graphite areas are wrongly identified as binder inside some graphite particles.\n",
    "- Regarding relative differences in the segmentation per phase, the conductive binder and porosity are the most uncertain phases. And the ones that evolve the most, in the good direction, by increasing training. Same as before. Looking at the relative differences, the graphite seems indeed to globally move marginally. Although from the maps we see that some consequent patches are not correctly labelled (not just the interfaces)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6928fd6",
   "metadata": {},
   "source": [
    "# Model comparison between untrained and trained with two other randomly selected slices and their adjacent slices (no manual annotation as ground truth)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b210779",
   "metadata": {},
   "source": [
    "Here is a comparison between the model in an untrained state (only rough annotation used, number 5272987912) and in a trained state (7-8 iterations with the human user, number 6501045458) as for the first part.\n",
    "The difference here is that there is no manual annotation to use as ground truth for the comparison.\n",
    "All 3 randomly selected slices (also excluding the training pool) are accompanied by adjacent slices (2 before and 2 after) in the full volume to have a bit more statistic and look a bit into slice-to-slice coherence (in the bulk classification, surfaces and interfaces will move)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfc95592",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_rough_1093 = io.imread(\"output_5272987912_s1093/*.tif\")\n",
    "images_rough_724 = io.imread(\"output_5272987912_s724/*.tif\")\n",
    "images_rough_1507 = io.imread(\"output_5272987912_s1507/*.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36491cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b148f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
